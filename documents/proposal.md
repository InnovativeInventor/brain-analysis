## Leading Question
Neuroimaging studies have shown that certain brain regions respond selectively to scene images. These brain areas are activated not only when we look at natural scene images, but also when we imagine them. There is evidence that two distinct brain networks are involved in scene-processing: the posterior region responsible for processing visual statistics of an image and the anterior region for retrieving long-term memory and navigating information (Baldassano et al., 2016). Using human functional magnetic reasoning imaging (fMRI) data of brain activity, we ask if the dynamics of the scene network differ under viewing and imagining conditions. In particular, we are interested in looking at the dissociation between the two networks. We hypothesize that both anterior and posterior networks will be activated in the viewing condition, whereas only the anterior region will be activated in the imagining condition. To quantify which regions of the brain are most activated in specific scenarios, we will measure which regions’ activations correlate with other regions the most. To investigate and quantify the communities/correlated regions in the brain, we will use the Girvan-Newman algorithm. We also will measure the authoritativeness of the regions using the PageRank algorithm, to determine which parts of the brain are “most important” or “most involved” for scene processing.
 
## Data

### Data Acquisition
We will be using fMRI data publicly available on Openneuro: https://openneuro.org/datasets/ds001506/versions/1.3.1. The dataset contains fMRI data collected from three subjects. We will only be using one subset of the data, specifically, from the natural scene viewing and imagining condition which contain roughly 40 GB of fMRI data in total (including auxiliary files).

### Dataset Format
There will be two sets of fMRI data, one for each of the two conditions (image viewing vs imagining). We will extract the brain signals recorded from specific regions of interest. The main body of raw data is in the nifti format, the standard format for storing and distributing brain imaging data. There is an additional header file specifying the acquisition parameter when the data were recorded and an additional text file keeping the behavioral data, such as when the subject was instructed to start imagining an image.
The main body of fMRI data contains multiple 3D matrices, each containing the activity of the brain at a specific time point. In our case, there are 227 time points in the imagining condition per run (one continuous chunk of time that the subject is scanned) with 20 runs in total and 239 time points for viewing images with 24 runs in total. The 3D matrices themselves are composed of voxels (volumetric pixels), the smallest unit of the brain that can be recorded. The size of our voxel is 2 * 2 * 2 mm, giving a 96 * 96 * 76 (voxel) matrix for the whole brain. We will decrease the resolution of our data in order to perform analysis on our data in a reasonable amount of time.

### Data Correction
We will be using analysis of functional neuroimages (AFNI (Cox, 1996)), an open-source neuroimaging data preprocessing tool to preprocess the fMRI data. The raw fMRI dataset will be submitted through the standard pipeline used in the functional connectivity literature: 
slice timing correction: each 3D brain volume was not take at a single shot, but curated from a series of 2D slices, we need to account for the temporal delay between the first and last acquisition;
motion correction: correct for subject’s head movements;
delineation of grey matter: find out where the actual neurons are;
spatial smoothing: to increase signal to noise ratio;
time series detrending: signal cleaning procedure to account for scanner noises. 
Then all subjects’ brains will be mapped onto the standard brain map (MNI152 T1 avg), where we can find the 5 predefined regions of interest: Parahippocampal place area (PPA), Hippocampus, caudal Intraparietal Lobule (cIPL), Retrosplenial Cortex (RSC), and Occipital place area (OPA near the transverse occipital sulcus). Time series in the voxels of these regions will be extracted and labeled with their coordinates for later reconstruction once we finish the subsequent analysis. 

Finally, with the information collected during the data collection process, we will only preserve time points relevant to the tasks we wish to examine. For example, if the subject was instructed to start imagining at time point 5, stop at time point 10, then start imagining the next one at time point 15, then we will discard the data between timepoints 10 and 15. Task relevant data from all 20 runs (or 24 runs in the image viewing case) will be concatenated together as the final activity profile. Each voxel, at this point, will have an activity profile. We calculate all possible pairwise connectivity using Pearson’s R correlation measure to produce our final graph. We will only construct the graph with some small top percentage of edges.

### Data Storage
After preprocessing, we will end up with N voxels (the specific number of voxels will be dependent on the data itself), and each of them will have two time series of activation values corresponding to the two conditions. We will then calculate the pairwise correlation between all the regions, producing N^2 correlations. We will only consider some top percentage of these connections. Our graph will consist of voxels as vertices, and strong correlations as edges between voxels. Our graph will be relatively sparse, as we will drop most pairwise correlations between voxels. Thus, we will use an adjacency list. The number of edges in the graph will be within some constant factor of N^2, so the storage complexity for this graph will be O(N^2). However, the storage cost in practice will be less than an adjacency matrix since this percentage will be extremely small.

## Algorithms
### PageRank algorithm
We will be using Google’s PageRank algorithm, a variant of Eigenvector centrality. It weighs brain regions based on the degree of connection with other brain regions. We will be applying PageRank to analyze network properties in the human brain. Typically, PageRank algorithms have been used in analyzing directed graphs, however we will be using it to analyze our undirected data. This will be done by treating each undirected edge as two directed edges. The advantage of this method is that we can identify important brain regions, and see if they are clustered or separated in any meaningful locations. Besides the actual graph, PageRank takes as input a number of iterations k and a damping factor. We will have to experiment to find appropriate values for these quantities in order to best balance execution & iteration time and the usefulness of our output. PageRank outputs a probability for each node in our graph. In the typical application of PageRank, this probability represents the probability a user will end up on a certain website. We will interpret this probability as the authority of a particular brain region. We will store this value on a per-node basis, and use it to print the most authoritative regions of the brain. For us, PageRank will have runtime complexity O(kN^2), where k is the number of iterations, since the number of edges will be linearly proportional to the number of vertices squared. The space complexity will be O(N).

### Girvan-Newman algorithm
The other algorithm we will be using is the Girvan-Newman algorithm to compute betweenness centrality to investigate the organization of brain networks. The normal input to Girvan-Newman is a graph whose edge values are distances. However, we would like highly central regions of the brain to be regions with high correlations with neighbors. Therefore, we will inverse each edge weight (f(x) = 1/x) before applying Girvan-Newman on our graph. The output of Girvan-Newman will be a set of connected components, all of which are subsets of our original graph. In other words, the output will be several communities in our original graph. We will store these as lists of nodes. As we will be using unweighted graphs, the complexity could be re-written from O(N^3) to O(N*M). However, for our use-case, M is proportional to N^2, so our theoretical running time is still O(N^3), even if M is in practice far smaller than N^2.

## Timeline
The following tasks must be completed for this project:
Data acquisition
Data correction (passing through AFNI pipeline)
PageRank implementation
Girvan-Newman implementation
Written report & final presentation
The fMRI pre-processing with take us some time, and we hope to complete it by April 15th. Once the pre-processing has been completed, we can begin implementing the algorithms. We will aim to implement PageRank by April 18th in time for the mid-project check-in, and Girvan-Newman by April 25th. This will give us just under 2 weeks to thoroughly test our algorithms, interpret our results, and create the final written report and presentation. If time permits, we plan to investigate any patterns or findings we discover in the dataset.
